---
title: "Regression and Cross Validation"
output: html_notebook
---

# Regression Analysis
The data we used can be found [here](https://data.ontario.ca/dataset/ontario-covid-19-outbreaks-data/resource/36048cc1-3c47-48ff-a49f-8c7840e32cc2)
```{r}
data = read.csv("~/36048cc1-3c47-48ff-a49f-8c7840e32cc2.csv")
head(data)
```
We wish to predict the number of cases based off the Public Health Unit (PHU) and the outbreak group.
We drop X_id since it is a unique identifier and has no correlation to the metric we want to predict. We also drop date since we will not be doing any time series analysis. We also drop phu_name to avoid redunandancy as we have already have an encoded version of it (phu_num). We now encode outbreak_group. We also drop all null values.
## Preprocessing

```{r}
# Preprocessing
data = data %>% select(-c(X_id, date, phu_name))
# Dropping null values
data = na.omit(data)
dim(data)
```

## Encoding
```{r}
data = data %>% mutate(outbreak_group = case_when(
  outbreak_group == "1 Congregate Care" ~ 0,
  outbreak_group == "2 Congregate Living" ~ 1,
  outbreak_group == "3 Education" ~ 2,
  outbreak_group == "4 Workplace" ~ 3,
  outbreak_group == "5 Recreational" ~ 4,
  outbreak_group == "6 Other/Unknown" ~ 5
))
head(data)
```
# Cross Validation
We decided to do a 70-30 split between train and test
```{r}
data=data %>% mutate(group_ind = sample(c("train","test"),
size=nrow(data),
prob = c(0.6,0.4),
replace = T))
head(data)
```
## Regression modelling
```{r}
model <- lm(number_ongoing_outbreaks ~ phu_num + outbreak_group, 
            data = data %>% filter(group_ind == "train"))

summary(model)
```
## k-fold Cross Validation
We do this with k = 5
```{r}
# Creating a fold_indicator (for 5 folds)
# 1. Create 5 random folds
set.seed(42)
data <- data %>%
  mutate(group_ind = sample(1:5, size = nrow(data), replace = TRUE))

# 2. Initialize MSE vector
mse_vec <- numeric(5)

# 3. Cross-validation loop
for (i in 1:5) {
  # Split data
  train_data <- data %>% filter(group_ind != i)
  test_data  <- data %>% filter(group_ind == i)

  # Fit model (example: predict number of ongoing outbreaks from phu_num)
  model <- lm(number_ongoing_outbreaks ~ phu_num + outbreak_group , data = train_data)

  # Predict on test set
  preds <- predict(model, newdata = test_data)

  # Calculate MSE for this fold
  mse_vec[i] <- mean((test_data$number_ongoing_outbreaks - preds)^2)
}

# View MSE for each fold
mse_vec

# Average MSE
mean(mse_vec)

```
So our MSE is 106.5697, which is actually not that bad if we consider the spread of COVID cases.

## Conclusion
In this analysis, we explored factors influencing the number of ongoing COVID-19 outbreaks in Ontario using data from the provincial open data portal. After cleaning and preprocessing the dataset—removing irrelevant columns (X_id, date, and phu_name), handling missing values, and encoding categorical variables—we built a regression model to assess the relationship between outbreak counts, Public Health Units (phu_num), and outbreak settings (outbreak_group). We first trained the model on a 70-30 split of the data and then validated its performance using 5-fold cross-validation. The average mean squared error (MSE) across folds was approximately 106.57, suggesting moderate predictive accuracy considering the variability in outbreak counts across the province.

The final regression model showed that both predictors were statistically significant (p < 2e-16). The intercept (4.15) represents the expected number of ongoing outbreaks in a baseline setting (Congregate Care) within the reference PHU. The coefficient for phu_num (0.0017) suggests only a minimal increase in predicted outbreaks per unit increase in PHU code, which is likely more administrative than geographic. More notably, the outbreak_group coefficient (-1.315) indicates a meaningful decrease in outbreaks as the setting category shifts from lower- to higher-numbered groups (e.g., from congregate care to recreational or unknown settings). However, the model’s R-squared value of 0.051 suggests that these variables explain only about 5.1% of the variance in outbreak counts, implying that additional factors—such as local transmission rates, public health interventions, or vaccination coverage—may be essential to improve model performance in future analyses.

